{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Fundamentos de Inteligencia Artificial ‚Äî Entrenamiento de Modelos\n",
    "\n",
    "**Instructor:** Alexander  \n",
    "**Duraci√≥n:** 3-4 horas  \n",
    "**Nivel:** Intermedio\n",
    "\n",
    "## üìã Objetivos de Aprendizaje\n",
    "\n",
    "Al finalizar este notebook, ser√°s capaz de:\n",
    "\n",
    "1. ‚úÖ Comprender el flujo completo de un proyecto de Machine Learning\n",
    "2. ‚úÖ Preparar y explorar datos de manera efectiva\n",
    "3. ‚úÖ Implementar y comparar m√∫ltiples algoritmos de ML\n",
    "4. ‚úÖ Evaluar modelos con m√©tricas apropiadas\n",
    "5. ‚úÖ Optimizar hiperpar√°metros de manera sistem√°tica\n",
    "6. ‚úÖ Desplegar modelos en producci√≥n\n",
    "\n",
    "## üìö Contenido\n",
    "\n",
    "1. Configuraci√≥n del entorno\n",
    "2. Flujo de trabajo en Machine Learning\n",
    "3. Exploraci√≥n y preparaci√≥n de datos\n",
    "4. Modelos de clasificaci√≥n (7+ algoritmos)\n",
    "5. Modelos de regresi√≥n (5+ algoritmos)\n",
    "6. Evaluaci√≥n y m√©tricas avanzadas\n",
    "7. Preprocesamiento y Feature Engineering\n",
    "8. Pipelines y automatizaci√≥n\n",
    "9. Optimizaci√≥n de hiperpar√°metros\n",
    "10. Manejo de desbalanceo de clases\n",
    "11. Validaci√≥n cruzada avanzada\n",
    "12. Guardado y despliegue de modelos\n",
    "13. Mejores pr√°cticas y tips profesionales\n",
    "14. Ejercicios pr√°cticos\n",
    "15. Proyecto final\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuraci√≥n del Entorno\n",
    "\n",
    "### Instalaci√≥n de dependencias\n",
    "\n",
    "Ejecuta esta celda si necesitas instalar las librer√≠as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta y ejecuta si necesitas instalar\n",
    "# !pip install scikit-learn pandas numpy matplotlib seaborn joblib xgboost lightgbm imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as b√°sicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# scikit-learn - Datasets\n",
    "from sklearn.datasets import load_iris, load_diabetes, load_breast_cancer, make_classification, make_regression\n",
    "\n",
    "# scikit-learn - Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# scikit-learn - Modelos de Clasificaci√≥n\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# scikit-learn - Modelos de Regresi√≥n\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# scikit-learn - M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Selecci√≥n de features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, SelectFromModel\n",
    "\n",
    "# Manejo de desbalanceo\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è imbalanced-learn no est√° instalado. Algunas funciones no estar√°n disponibles.\")\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "\n",
    "# Persistencia\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Versiones\n",
    "import sklearn\n",
    "print('‚úÖ Librer√≠as cargadas exitosamente')\n",
    "print(f'üì¶ NumPy: {np.__version__}')\n",
    "print(f'üì¶ Pandas: {pd.__version__}')\n",
    "print(f'üì¶ Scikit-learn: {sklearn.__version__}')\n",
    "print(f'üì¶ Matplotlib: {plt.matplotlib.__version__}')\n",
    "print(f'üì¶ Seaborn: {sns.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Flujo de Trabajo en Machine Learning\n",
    "\n",
    "### üîÑ Pipeline Completo\n",
    "\n",
    "```\n",
    "1. DEFINICI√ìN DEL PROBLEMA\n",
    "   ‚îú‚îÄ ¬øClasificaci√≥n o Regresi√≥n?\n",
    "   ‚îú‚îÄ ¬øQu√© m√©trica de √©xito?\n",
    "   ‚îî‚îÄ ¬øQu√© restricciones tengo?\n",
    "\n",
    "2. RECOLECCI√ìN DE DATOS\n",
    "   ‚îú‚îÄ Fuentes de datos\n",
    "   ‚îú‚îÄ Calidad y cantidad\n",
    "   ‚îî‚îÄ Consideraciones √©ticas\n",
    "\n",
    "3. EXPLORACI√ìN (EDA)\n",
    "   ‚îú‚îÄ Estad√≠sticas descriptivas\n",
    "   ‚îú‚îÄ Visualizaciones\n",
    "   ‚îú‚îÄ Correlaciones\n",
    "   ‚îî‚îÄ Detecci√≥n de outliers\n",
    "\n",
    "4. PREPARACI√ìN DE DATOS\n",
    "   ‚îú‚îÄ Limpieza (valores faltantes, duplicados)\n",
    "   ‚îú‚îÄ Transformaciones\n",
    "   ‚îú‚îÄ Codificaci√≥n de variables categ√≥ricas\n",
    "   ‚îî‚îÄ Feature Engineering\n",
    "\n",
    "5. DIVISI√ìN DE DATOS\n",
    "   ‚îú‚îÄ Train / Test (t√≠picamente 70-80% / 20-30%)\n",
    "   ‚îú‚îÄ Train / Validation / Test (60% / 20% / 20%)\n",
    "   ‚îî‚îÄ Estratificaci√≥n si es necesario\n",
    "\n",
    "6. ENTRENAMIENTO\n",
    "   ‚îú‚îÄ Selecci√≥n de modelos\n",
    "   ‚îú‚îÄ Entrenamiento (fit)\n",
    "   ‚îî‚îÄ Validaci√≥n cruzada\n",
    "\n",
    "7. EVALUACI√ìN\n",
    "   ‚îú‚îÄ M√©tricas apropiadas\n",
    "   ‚îú‚îÄ Matriz de confusi√≥n\n",
    "   ‚îú‚îÄ Curvas ROC/PR\n",
    "   ‚îî‚îÄ An√°lisis de errores\n",
    "\n",
    "8. OPTIMIZACI√ìN\n",
    "   ‚îú‚îÄ Ajuste de hiperpar√°metros\n",
    "   ‚îú‚îÄ Feature selection\n",
    "   ‚îî‚îÄ Ensemble methods\n",
    "\n",
    "9. VALIDACI√ìN FINAL\n",
    "   ‚îú‚îÄ Evaluaci√≥n en test set\n",
    "   ‚îú‚îÄ Comparaci√≥n con baseline\n",
    "   ‚îî‚îÄ An√°lisis de sesgo/varianza\n",
    "\n",
    "10. DESPLIEGUE\n",
    "    ‚îú‚îÄ Guardar modelo\n",
    "    ‚îú‚îÄ Documentaci√≥n\n",
    "    ‚îú‚îÄ Monitoreo\n",
    "    ‚îî‚îÄ Actualizaci√≥n continua\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Exploraci√≥n y Preparaci√≥n de Datos\n",
    "\n",
    "### Dataset: Iris (Clasificaci√≥n Multiclase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset Iris\n",
    "iris = load_iris(as_frame=True)\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Crear DataFrame completo para an√°lisis\n",
    "df_iris = X_iris.copy()\n",
    "df_iris['target'] = y_iris\n",
    "df_iris['species'] = df_iris['target'].map(lambda x: target_names[x])\n",
    "\n",
    "print(\"üìä Dataset Iris cargado\")\n",
    "print(f\"   Dimensiones: {df_iris.shape}\")\n",
    "print(f\"   Features: {len(feature_names)}\")\n",
    "print(f\"   Clases: {len(target_names)} - {list(target_names)}\")\n",
    "print(\"\\nüîç Primeras filas:\")\n",
    "df_iris.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"üìà Estad√≠sticas Descriptivas:\\n\")\n",
    "print(df_iris.describe())\n",
    "\n",
    "print(\"\\nüî¢ Informaci√≥n del Dataset:\\n\")\n",
    "print(df_iris.info())\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Valores faltantes:\")\n",
    "print(df_iris.isnull().sum())\n",
    "\n",
    "print(\"\\nüìä Distribuci√≥n de clases:\")\n",
    "print(df_iris['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "df_iris['species'].value_counts().plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Distribuci√≥n de Especies', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].set_xlabel('Especie')\n",
    "\n",
    "# Pairplot simplificado (2 features)\n",
    "for species in df_iris['species'].unique():\n",
    "    subset = df_iris[df_iris['species'] == species]\n",
    "    axes[0, 1].scatter(subset['sepal length (cm)'], subset['sepal width (cm)'], \n",
    "                       label=species, alpha=0.6, s=50)\n",
    "axes[0, 1].set_xlabel('Sepal Length (cm)')\n",
    "axes[0, 1].set_ylabel('Sepal Width (cm)')\n",
    "axes[0, 1].set_title('Sepal Length vs Width', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "df_iris.boxplot(column='petal length (cm)', by='species', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Petal Length por Especie', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Especie')\n",
    "axes[1, 0].set_ylabel('Petal Length (cm)')\n",
    "plt.sca(axes[1, 0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Matriz de correlaci√≥n\n",
    "corr_matrix = df_iris[feature_names].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', ax=axes[1, 1], \n",
    "            square=True, cbar_kws={'shrink': 0.8})\n",
    "axes[1, 1].set_title('Matriz de Correlaci√≥n', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaciones generadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisi√≥n de Datos\n",
    "\n",
    "**Buenas pr√°cticas:**\n",
    "- Usar `stratify` para mantener la proporci√≥n de clases\n",
    "- Fijar `random_state` para reproducibilidad\n",
    "- Separar test set ANTES de cualquier preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n estratificada (mantiene proporci√≥n de clases)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, \n",
    "    test_size=0.25,      # 75% train, 25% test\n",
    "    random_state=42,     # Reproducibilidad\n",
    "    stratify=y_iris      # Mantiene proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(\"‚úÇÔ∏è Divisi√≥n de datos completada\")\n",
    "print(f\"   Train: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X_iris)*100:.1f}%)\")\n",
    "print(f\"   Test:  {X_test.shape[0]} muestras ({X_test.shape[0]/len(X_iris)*100:.1f}%)\")\n",
    "print(\"\\nüìä Distribuci√≥n de clases en Train:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(\"\\nüìä Distribuci√≥n de clases en Test:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Modelos de Clasificaci√≥n\n",
    "\n",
    "### Comparaci√≥n de M√∫ltiples Algoritmos\n",
    "\n",
    "Entrenaremos y compararemos 10+ algoritmos de clasificaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de modelos a comparar\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'Ridge Classifier': RidgeClassifier(random_state=42),\n",
    "    'SGD Classifier': SGDClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "print(f\"üéØ {len(classification_models)} modelos de clasificaci√≥n listos para entrenar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y Evaluaci√≥n con Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de todos los modelos\n",
    "results = []\n",
    "\n",
    "print(\"üöÄ Entrenando modelos...\\n\")\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    # Crear pipeline con escalado + modelo\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalizaci√≥n\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Validaci√≥n cruzada (5-fold)\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'CV Mean': cv_mean,\n",
    "        'CV Std': cv_std\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {name:25s} | Acc: {accuracy:.4f} | CV: {cv_mean:.4f} ¬± {cv_std:.4f}\")\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä RESUMEN DE RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico comparativo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "results_df_sorted = results_df.sort_values('Accuracy')\n",
    "axes[0].barh(results_df_sorted['Model'], results_df_sorted['Accuracy'], color='steelblue')\n",
    "axes[0].set_xlabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Comparaci√≥n de Accuracy por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(x=results_df_sorted['Accuracy'].mean(), color='red', linestyle='--', \n",
    "                label=f\"Media: {results_df_sorted['Accuracy'].mean():.3f}\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# M√©tricas m√∫ltiples del mejor modelo\n",
    "best_model_row = results_df.iloc[0]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "values = [best_model_row[m] for m in metrics]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "bars = axes[1].bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('Score', fontsize=12)\n",
    "axes[1].set_title(f'M√©tricas del Mejor Modelo: {best_model_row[\"Model\"]}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1.1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Agregar valores sobre las barras\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis Detallado del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = classification_models[best_model_name]\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "\n",
    "print(f\"üèÜ Mejor modelo: {best_model_name}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_best, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Visualizaci√≥n mejorada\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names,\n",
    "            cbar_kws={'label': 'Cantidad'})\n",
    "plt.title(f'Matriz de Confusi√≥n - {best_model_name}', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Valor Real', fontsize=12)\n",
    "plt.xlabel('Predicci√≥n', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de errores\n",
    "print(\"\\nüîç An√°lisis de la Matriz de Confusi√≥n:\")\n",
    "print(f\"   Diagonal (predicciones correctas): {cm.diagonal().sum()} / {cm.sum()}\")\n",
    "print(f\"   Errores totales: {cm.sum() - cm.diagonal().sum()}\")\n",
    "print(f\"   Accuracy: {cm.diagonal().sum() / cm.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas ROC (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarizar las etiquetas para ROC multiclase\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Obtener probabilidades de predicci√≥n\n",
    "if hasattr(best_pipeline, \"predict_proba\"):\n",
    "    y_score = best_pipeline.predict_proba(X_test)\n",
    "elif hasattr(best_pipeline, \"decision_function\"):\n",
    "    y_score = best_pipeline.decision_function(X_test)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è El modelo no soporta probabilidades o decision_function\")\n",
    "    y_score = None\n",
    "\n",
    "if y_score is not None:\n",
    "    # Calcular ROC para cada clase\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                label=f'{target_names[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.5)')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "    plt.title(f'Curvas ROC (One-vs-Rest) - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìà AUC Scores:\")\n",
    "    for i in range(n_classes):\n",
    "        print(f\"   {target_names[i]:15s}: {roc_auc[i]:.4f}\")\n",
    "    print(f\"   Promedio (macro):  {np.mean(list(roc_auc.values())):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Modelos de Regresi√≥n\n",
    "\n",
    "### Dataset: Diabetes (Regresi√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "X_diabetes = diabetes.data\n",
    "y_diabetes = diabetes.target\n",
    "\n",
    "df_diabetes = X_diabetes.copy()\n",
    "df_diabetes['target'] = y_diabetes\n",
    "\n",
    "print(\"üìä Dataset Diabetes cargado\")\n",
    "print(f\"   Dimensiones: {df_diabetes.shape}\")\n",
    "print(f\"   Features: {X_diabetes.shape[1]}\")\n",
    "print(f\"\\nüéØ Target (progresi√≥n de diabetes):\")\n",
    "print(f\"   Min: {y_diabetes.min():.2f}\")\n",
    "print(f\"   Max: {y_diabetes.max():.2f}\")\n",
    "print(f\"   Mean: {y_diabetes.mean():.2f}\")\n",
    "print(f\"   Std: {y_diabetes.std():.2f}\")\n",
    "\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n de datos\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_diabetes, y_diabetes, \n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÇÔ∏è Divisi√≥n completada: {Xr_train.shape[0]} train / {Xr_test.shape[0]} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de Modelos de Regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos de regresi√≥n\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (L2)': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso (L1)': Lasso(alpha=1.0, random_state=42),\n",
    "    'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42),\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR (RBF)': SVR(kernel='rbf'),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(f\"üéØ {len(regression_models)} modelos de regresi√≥n listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y evaluaci√≥n\n",
    "regression_results = []\n",
    "\n",
    "print(\"üöÄ Entrenando modelos de regresi√≥n...\\n\")\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    # Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar\n",
    "    pipeline.fit(Xr_train, yr_train)\n",
    "    \n",
    "    # Predecir\n",
    "    yr_pred = pipeline.predict(Xr_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    mse = mean_squared_error(yr_test, yr_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(yr_test, yr_pred)\n",
    "    r2 = r2_score(yr_test, yr_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, Xr_train, yr_train, cv=5, \n",
    "                                scoring='neg_mean_squared_error')\n",
    "    cv_rmse_mean = np.sqrt(-cv_scores.mean())\n",
    "    cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    regression_results.append({\n",
    "        'Model': name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'CV RMSE': cv_rmse_mean\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {name:22s} | RMSE: {rmse:6.2f} | R¬≤: {r2:6.3f} | CV RMSE: {cv_rmse_mean:6.2f}\")\n",
    "\n",
    "# DataFrame de resultados\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "regression_results_df = regression_results_df.sort_values('RMSE').reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"üìä RESUMEN DE RESULTADOS - REGRESI√ìN\")\n",
    "print(\"=\"*90)\n",
    "print(regression_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo de regresi√≥n\n",
    "best_reg_name = regression_results_df.iloc[0]['Model']\n",
    "best_reg_model = regression_models[best_reg_name]\n",
    "\n",
    "best_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', best_reg_model)\n",
    "])\n",
    "\n",
    "best_reg_pipeline.fit(Xr_train, yr_train)\n",
    "yr_pred_best = best_reg_pipeline.predict(Xr_test)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Gr√°fico 1: Predicho vs Real\n",
    "axes[0].scatter(yr_test, yr_pred_best, alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "axes[0].plot([yr_test.min(), yr_test.max()], [yr_test.min(), yr_test.max()], \n",
    "             'r--', lw=2, label='Predicci√≥n perfecta')\n",
    "axes[0].set_xlabel('Valor Real', fontsize=12)\n",
    "axes[0].set_ylabel('Predicci√≥n', fontsize=12)\n",
    "axes[0].set_title(f'Predicho vs Real - {best_reg_name}', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Distribuci√≥n de Residuos\n",
    "residuals = yr_test - yr_pred_best\n",
    "axes[1].scatter(yr_pred_best, residuals, alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicci√≥n', fontsize=12)\n",
    "axes[1].set_ylabel('Residuos (Real - Predicho)', fontsize=12)\n",
    "axes[1].set_title('An√°lisis de Residuos', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de residuos\n",
    "print(\"\\nüìä Estad√≠sticas de Residuos:\")\n",
    "print(f\"   Media: {residuals.mean():.4f} (cercano a 0 es ideal)\")\n",
    "print(f\"   Desv. Std: {residuals.std():.4f}\")\n",
    "print(f\"   Min: {residuals.min():.4f}\")\n",
    "print(f\"   Max: {residuals.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Feature Engineering y Selecci√≥n\n",
    "\n",
    "### Importancia de Features (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest para obtener importancia\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener importancias\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"üåü Importancia de Features (Random Forest):\\n\")\n",
    "print(feature_importances.to_string(index=False))\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances['feature'], feature_importances['importance'], color='teal')\n",
    "plt.xlabel('Importancia', fontsize=12)\n",
    "plt.title('Importancia de Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci√≥n de Features con SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las mejores 2 features\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Features seleccionadas\n",
    "selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"‚úÖ Features seleccionadas (k=2): {selected_features}\")\n",
    "\n",
    "# Entrenar modelo con features seleccionadas\n",
    "lr_selected = LogisticRegression(max_iter=500, random_state=42)\n",
    "lr_selected.fit(X_train_selected, y_train)\n",
    "y_pred_selected = lr_selected.predict(X_test_selected)\n",
    "\n",
    "print(f\"\\nüìä Accuracy con todas las features: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"üìä Accuracy con 2 mejores features: {accuracy_score(y_test, y_pred_selected):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Optimizaci√≥n de Hiperpar√°metros\n",
    "\n",
    "### GridSearchCV - B√∫squeda Exhaustiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir espacio de b√∫squeda\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear'],\n",
    "    'classifier__max_iter': [200, 500, 1000],\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Pipeline base\n",
    "pipeline_grid = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_grid,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üîç Iniciando GridSearchCV...\")\n",
    "print(f\"   Total de combinaciones: {len(param_grid['classifier__C']) * len(param_grid['classifier__solver']) * len(param_grid['classifier__max_iter'])}\")\n",
    "print(f\"   CV folds: 5\\n\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")\n",
    "print(f\"\\nüèÜ Mejor score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\n‚öôÔ∏è Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en test set\n",
    "y_pred_grid = grid_search.predict(X_test)\n",
    "print(f\"\\nüìä Accuracy en test set: {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "\n",
    "# Top 10 configuraciones\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "top_configs = cv_results.nsmallest(10, 'rank_test_score')[[\n",
    "    'rank_test_score', 'mean_test_score', 'std_test_score', 'params'\n",
    "]]\n",
    "\n",
    "print(\"\\nüìã Top 10 Configuraciones:\\n\")\n",
    "for idx, row in top_configs.iterrows():\n",
    "    print(f\"Rank {int(row['rank_test_score'])}: Score {row['mean_test_score']:.4f} ¬± {row['std_test_score']:.4f}\")\n",
    "    print(f\"   Params: {row['params']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV - B√∫squeda Aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Distribuciones para Random Forest\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': randint(50, 200),\n",
    "    'classifier__max_depth': [None, 5, 10, 15, 20],\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 10),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "pipeline_random = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline_random,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # N√∫mero de combinaciones a probar\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üé≤ Iniciando RandomizedSearchCV...\\n\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ RandomizedSearchCV completado\")\n",
    "print(f\"\\nüèÜ Mejor score (CV): {random_search.best_score_:.4f}\")\n",
    "print(f\"\\n‚öôÔ∏è Mejores hiperpar√°metros:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "# Test set\n",
    "y_pred_random = random_search.predict(X_test)\n",
    "print(f\"\\nüìä Accuracy en test set: {accuracy_score(y_test, y_pred_random):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Manejo de Datos Desbalanceados\n",
    "\n",
    "### Crear dataset desbalanceado sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset desbalanceado\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # 90% clase 0, 10% clase 1\n",
    "    flip_y=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"üìä Dataset desbalanceado generado\")\n",
    "print(f\"   Total: {len(y_imb)} muestras\")\n",
    "print(\"\\n   Distribuci√≥n de clases:\")\n",
    "unique, counts = np.unique(y_imb, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"   Clase {cls}: {count} ({count/len(y_imb)*100:.1f}%)\")\n",
    "\n",
    "# Divisi√≥n\n",
    "X_imb_train, X_imb_test, y_imb_train, y_imb_test = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.25, random_state=42, stratify=y_imb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√©cnica 1: Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin balanceo\n",
    "lr_no_balance = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_no_balance.fit(X_imb_train, y_imb_train)\n",
    "y_pred_no_balance = lr_no_balance.predict(X_imb_test)\n",
    "\n",
    "# Con class_weight='balanced'\n",
    "lr_balanced = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "lr_balanced.fit(X_imb_train, y_imb_train)\n",
    "y_pred_balanced = lr_balanced.predict(X_imb_test)\n",
    "\n",
    "print(\"‚öñÔ∏è Comparaci√≥n: Sin balanceo vs Con class_weight\\n\")\n",
    "print(\"SIN BALANCEO:\")\n",
    "print(classification_report(y_imb_test, y_pred_no_balance))\n",
    "print(\"\\nCON CLASS_WEIGHT='balanced':\")\n",
    "print(classification_report(y_imb_test, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√©cnica 2: SMOTE (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMBLEARN_AVAILABLE:\n",
    "    # Aplicar SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_imb_train_smote, y_imb_train_smote = smote.fit_resample(X_imb_train, y_imb_train)\n",
    "    \n",
    "    print(\"üîÑ SMOTE aplicado\")\n",
    "    print(f\"   Antes: {len(y_imb_train)} muestras\")\n",
    "    print(f\"   Despu√©s: {len(y_imb_train_smote)} muestras\")\n",
    "    print(\"\\n   Nueva distribuci√≥n:\")\n",
    "    unique, counts = np.unique(y_imb_train_smote, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"   Clase {cls}: {count} ({count/len(y_imb_train_smote)*100:.1f}%)\")\n",
    "    \n",
    "    # Entrenar con datos balanceados\n",
    "    lr_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr_smote.fit(X_imb_train_smote, y_imb_train_smote)\n",
    "    y_pred_smote = lr_smote.predict(X_imb_test)\n",
    "    \n",
    "    print(\"\\nüìä Resultados con SMOTE:\")\n",
    "    print(classification_report(y_imb_test, y_pred_smote))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è imbalanced-learn no disponible. Instala con: pip install imbalanced-learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Validaci√≥n Cruzada Avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes estrategias de CV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Modelo a evaluar\n",
    "model_cv = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# M√©tricas m√∫ltiples\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted',\n",
    "    'f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(\n",
    "    model_cv, X_train, y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"üìä Resultados de Validaci√≥n Cruzada (5-fold)\\n\")\n",
    "print(\"=\"*60)\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    train_scores = cv_results[f'train_{metric}']\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    \n",
    "    print(f\"{metric.upper():12s}:\")\n",
    "    print(f\"  Train: {train_scores.mean():.4f} ¬± {train_scores.std():.4f}\")\n",
    "    print(f\"  Test:  {test_scores.mean():.4f} ¬± {test_scores.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Calcular curva de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    X_train, y_train,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calcular media y desviaci√≥n\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='r', label='Train Score')\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='g', label='Cross-validation Score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, \n",
    "                 alpha=0.1, color='g')\n",
    "\n",
    "plt.xlabel('Tama√±o del conjunto de entrenamiento', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Curva de Aprendizaje - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Interpretaci√≥n:\")\n",
    "print(\"   - Gap grande entre train y CV ‚Üí Overfitting\")\n",
    "print(\"   - Ambas curvas bajas ‚Üí Underfitting\")\n",
    "print(\"   - Ambas curvas altas y cercanas ‚Üí Buen ajuste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîü Guardado y Despliegue de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio para modelos\n",
    "import os\n",
    "model_dir = '/mnt/user-data/outputs'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Informaci√≥n del modelo\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'sklearn_version': sklearn.__version__,\n",
    "    'accuracy': float(results_df.iloc[0]['Accuracy']),\n",
    "    'f1_score': float(results_df.iloc[0]['F1-Score']),\n",
    "    'features': feature_names,\n",
    "    'target_names': list(target_names),\n",
    "    'hyperparameters': best_pipeline.named_steps['classifier'].get_params()\n",
    "}\n",
    "\n",
    "# Guardar modelo con joblib (recomendado)\n",
    "model_path = os.path.join(model_dir, 'best_model_iris.joblib')\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "print(f\"‚úÖ Modelo guardado: {model_path}\")\n",
    "\n",
    "# Guardar metadata\n",
    "import json\n",
    "metadata_path = os.path.join(model_dir, 'model_info.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(f\"‚úÖ Metadata guardada: {metadata_path}\")\n",
    "\n",
    "# Guardar con pickle (alternativa)\n",
    "pickle_path = os.path.join(model_dir, 'best_model_iris.pkl')\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(best_pipeline, f)\n",
    "print(f\"‚úÖ Modelo guardado (pickle): {pickle_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar y Usar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(\"‚úÖ Modelo cargado exitosamente\\n\")\n",
    "\n",
    "# Hacer predicciones\n",
    "sample_data = X_test.iloc[:5]\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "probabilities = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "print(\"üîÆ Predicciones en nuevos datos:\\n\")\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "    print(f\"Muestra {i+1}:\")\n",
    "    print(f\"  Predicci√≥n: {target_names[pred]}\")\n",
    "    print(f\"  Probabilidades:\")\n",
    "    for j, prob in enumerate(probs):\n",
    "        print(f\"    {target_names[j]:15s}: {prob:.4f} ({prob*100:.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ Mejores Pr√°cticas y Tips\n",
    "\n",
    "### ‚úÖ DO's (Hacer)\n",
    "\n",
    "1. **Reproducibilidad**\n",
    "   - Siempre fijar `random_state` en modelos y splits\n",
    "   - Documentar versiones de librer√≠as\n",
    "   - Guardar seeds y configuraciones\n",
    "\n",
    "2. **Preprocesamiento**\n",
    "   - Usar Pipelines para evitar data leakage\n",
    "   - Escalar features DESPU√âS del split\n",
    "   - Documentar transformaciones aplicadas\n",
    "\n",
    "3. **Validaci√≥n**\n",
    "   - Usar validaci√≥n cruzada\n",
    "   - Mantener test set intocado hasta el final\n",
    "   - Estratificar si hay desbalanceo\n",
    "\n",
    "4. **M√©tricas**\n",
    "   - Elegir m√©tricas apropiadas al problema\n",
    "   - Reportar m√∫ltiples m√©tricas\n",
    "   - Considerar el contexto del negocio\n",
    "\n",
    "5. **Documentaci√≥n**\n",
    "   - Documentar decisiones y experimentos\n",
    "   - Guardar metadata con modelos\n",
    "   - Versionar modelos y datasets\n",
    "\n",
    "### ‚ùå DON'Ts (No hacer)\n",
    "\n",
    "1. **Data Leakage**\n",
    "   - No usar informaci√≥n del test en el train\n",
    "   - No escalar usando estad√≠sticas del dataset completo\n",
    "   - No hacer feature engineering con datos futuros\n",
    "\n",
    "2. **Overfitting**\n",
    "   - No confiar solo en accuracy del train\n",
    "   - No ignorar la validaci√≥n cruzada\n",
    "   - No usar modelos muy complejos sin regularizaci√≥n\n",
    "\n",
    "3. **Evaluaci√≥n**\n",
    "   - No usar solo accuracy en datos desbalanceados\n",
    "   - No optimizar en el test set\n",
    "   - No ignorar el an√°lisis de errores\n",
    "\n",
    "4. **Generalizaci√≥n**\n",
    "   - No asumir que CV = performance real\n",
    "   - No ignorar la distribuci√≥n de datos en producci√≥n\n",
    "   - No olvidar monitorear el modelo en producci√≥n\n",
    "\n",
    "### üéØ Checklist Pre-Despliegue\n",
    "\n",
    "- [ ] Modelo entrenado con mejores pr√°cticas\n",
    "- [ ] Validaci√≥n cruzada realizada\n",
    "- [ ] Test set evaluado\n",
    "- [ ] M√©tricas documentadas\n",
    "- [ ] An√°lisis de errores completado\n",
    "- [ ] Modelo guardado con metadata\n",
    "- [ ] Pipeline de preprocesamiento incluido\n",
    "- [ ] Documentaci√≥n completa\n",
    "- [ ] C√≥digo versionado\n",
    "- [ ] Plan de monitoreo definido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Breast Cancer Classification\n",
    "\n",
    "**Objetivo:** Predecir si un tumor es maligno o benigno\n",
    "\n",
    "**Tareas:**\n",
    "1. Cargar el dataset `load_breast_cancer()`\n",
    "2. Realizar EDA completo\n",
    "3. Comparar al menos 5 modelos\n",
    "4. Optimizar el mejor modelo con GridSearchCV\n",
    "5. Evaluar con m√∫ltiples m√©tricas\n",
    "6. Generar matriz de confusi√≥n y curva ROC\n",
    "7. Guardar el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU C√ìDIGO AQU√ç\n",
    "# Espacio para resolver el ejercicio 1\n",
    "\n",
    "# Pista: breast_cancer = load_breast_cancer(as_frame=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Regresi√≥n con Feature Engineering\n",
    "\n",
    "**Objetivo:** Mejorar el modelo de regresi√≥n de Diabetes\n",
    "\n",
    "**Tareas:**\n",
    "1. Crear features polinomiales de grado 2\n",
    "2. Aplicar selecci√≥n de features\n",
    "3. Comparar modelos lineales vs tree-based\n",
    "4. Evaluar con m√∫ltiples m√©tricas (MSE, MAE, R¬≤)\n",
    "5. Analizar residuos\n",
    "6. Documentar mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU C√ìDIGO AQU√ç\n",
    "# Espacio para resolver el ejercicio 2\n",
    "\n",
    "# Pista: from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Pipeline Completo\n",
    "\n",
    "**Objetivo:** Crear un pipeline robusto con datos mixtos\n",
    "\n",
    "**Tareas:**\n",
    "1. Generar dataset con features num√©ricas y categ√≥ricas\n",
    "2. Implementar ColumnTransformer\n",
    "3. Manejar valores faltantes\n",
    "4. Crear pipeline completo\n",
    "5. Optimizar hiperpar√°metros\n",
    "6. Guardar pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU C√ìDIGO AQU√ç\n",
    "# Espacio para resolver el ejercicio 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ Proyecto Final: Sistema Completo de ML\n",
    "\n",
    "### üéØ Descripci√≥n del Proyecto\n",
    "\n",
    "Desarrollar un sistema completo de Machine Learning que incluya:\n",
    "\n",
    "1. **Carga y exploraci√≥n de datos**\n",
    "2. **Preprocesamiento robusto**\n",
    "3. **Comparaci√≥n de m√∫ltiples modelos**\n",
    "4. **Optimizaci√≥n de hiperpar√°metros**\n",
    "5. **Evaluaci√≥n exhaustiva**\n",
    "6. **Guardado y documentaci√≥n**\n",
    "\n",
    "### üìã Requisitos\n",
    "\n",
    "- Usar un dataset real (puede ser de Kaggle o sklearn)\n",
    "- Implementar al menos 5 modelos diferentes\n",
    "- Crear Pipeline completo\n",
    "- Incluir validaci√≥n cruzada\n",
    "- Generar visualizaciones informativas\n",
    "- Documentar todo el proceso\n",
    "- Guardar modelo final con metadata\n",
    "\n",
    "### üèÜ Criterios de Evaluaci√≥n\n",
    "\n",
    "1. **Calidad del c√≥digo** (20%)\n",
    "2. **An√°lisis exploratorio** (15%)\n",
    "3. **Preprocesamiento** (15%)\n",
    "4. **Modelado** (25%)\n",
    "5. **Evaluaci√≥n** (15%)\n",
    "6. **Documentaci√≥n** (10%)\n",
    "\n",
    "### üí° Datasets Sugeridos\n",
    "\n",
    "- Titanic (clasificaci√≥n)\n",
    "- House Prices (regresi√≥n)\n",
    "- Credit Card Fraud (clasificaci√≥n desbalanceada)\n",
    "- Wine Quality (clasificaci√≥n multiclase)\n",
    "\n",
    "¬°Buena suerte! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROYECTO FINAL - TU C√ìDIGO AQU√ç\n",
    "\n",
    "# 1. Cargar datos\n",
    "\n",
    "\n",
    "# 2. EDA\n",
    "\n",
    "\n",
    "# 3. Preprocesamiento\n",
    "\n",
    "\n",
    "# 4. Modelado\n",
    "\n",
    "\n",
    "# 5. Evaluaci√≥n\n",
    "\n",
    "\n",
    "# 6. Guardado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ Referencias y Recursos Adicionales\n",
    "\n",
    "### üìö Documentaci√≥n Oficial\n",
    "\n",
    "- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [Scikit-learn API Reference](https://scikit-learn.org/stable/modules/classes.html)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [NumPy Documentation](https://numpy.org/doc/)\n",
    "- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "\n",
    "### üìñ Libros Recomendados\n",
    "\n",
    "- \"Hands-On Machine Learning\" - Aur√©lien G√©ron\n",
    "- \"Introduction to Machine Learning with Python\" - Andreas M√ºller\n",
    "- \"Python Data Science Handbook\" - Jake VanderPlas\n",
    "- \"The Elements of Statistical Learning\" - Hastie, Tibshirani, Friedman\n",
    "\n",
    "### üéì Cursos Online\n",
    "\n",
    "- [Coursera: Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)\n",
    "- [Fast.ai: Practical Deep Learning](https://www.fast.ai/)\n",
    "- [Google's Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course)\n",
    "\n",
    "### üõ†Ô∏è Herramientas √ötiles\n",
    "\n",
    "- [Kaggle](https://www.kaggle.com/) - Datasets y competencias\n",
    "- [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php) - Datasets cl√°sicos\n",
    "- [Papers With Code](https://paperswithcode.com/) - State of the art\n",
    "\n",
    "### üí¨ Comunidades\n",
    "\n",
    "- [Stack Overflow - Machine Learning](https://stackoverflow.com/questions/tagged/machine-learning)\n",
    "- [Reddit - r/MachineLearning](https://www.reddit.com/r/MachineLearning/)\n",
    "- [Kaggle Forums](https://www.kaggle.com/discussion)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ ¬°Felicitaciones!\n",
    "\n",
    "Has completado el notebook de Fundamentos de IA. Ahora tienes las herramientas necesarias para:\n",
    "\n",
    "‚úÖ Preparar y explorar datos  \n",
    "‚úÖ Entrenar m√∫ltiples modelos  \n",
    "‚úÖ Evaluar y comparar resultados  \n",
    "‚úÖ Optimizar hiperpar√°metros  \n",
    "‚úÖ Desplegar modelos en producci√≥n  \n",
    "\n",
    "**Pr√≥ximos pasos:**\n",
    "1. Practicar con datasets reales\n",
    "2. Participar en competencias de Kaggle\n",
    "3. Profundizar en temas avanzados (Deep Learning, NLP, Computer Vision)\n",
    "4. Contribuir a proyectos open source\n",
    "\n",
    "**¬°Sigue aprendiendo y construyendo! üöÄ**\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook creado por Alexander para el curso de Fundamentos de IA*  \n",
    "*√öltima actualizaci√≥n: Noviembre 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
